{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Пункт 2\n",
    "ff = pd.read_csv('SMSSpamCollection.txt', sep='\\t', names=['label','text'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Пункт 3\n",
    "labels = ff['label'].values\n",
    "texts = ff['text'].values\n",
    "lab_codes = np.array(map(lambda x: 1 if x == 'spam' else 0, labels))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Пункт 4\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "\n",
    "vec = CountVectorizer() \n",
    "\n",
    "X = vec.fit_transform(texts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Kirill\\Anaconda2\\lib\\site-packages\\sklearn\\cross_validation.py:44: DeprecationWarning: This module was deprecated in version 0.18 in favor of the model_selection module into which all the refactored classes and functions are moved. Also note that the interface of the new CV iterators are different from that of this module. This module will be removed in 0.20.\n",
      "  \"This module will be removed in 0.20.\", DeprecationWarning)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.cross_validation import cross_val_score\n",
    "from sklearn.linear_model import LogisticRegression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.932640298361\n"
     ]
    }
   ],
   "source": [
    "# Пункт 5\n",
    "print np.mean(cross_val_score(LogisticRegression(), X, lab_codes, cv=10, scoring='f1'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Пункт 6"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "clf = LogisticRegression().fit(X, lab_codes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "X_t = [\"FreeMsg:\tTxt:\tCALL\tto\tNo:\t86888\t&\tclaim\tyour\treward\tof\t3\thours\ttalk\ttime\tto\tuse\tfrom\tyour\tphone\tnow!\tSubscribe6GB\",\n",
    "\"FreeMsg:\tTxt:\tclaim\tyour\treward\tof\t3\thours\ttalk\ttime\",\n",
    "\"Have\tyou\tvisited\tthe\tlast\tlecture\ton\tphysics?\",\n",
    "\"Have\tyou\tvisited\tthe\tlast\tlecture\ton\tphysics?\tJust\tbuy\tthis\tbook\tand\tyou\twill\thave\tall\tmaterials!\tOnly\t99$\",\n",
    "\"Only\t99$\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1 1 0 0 0\n"
     ]
    }
   ],
   "source": [
    "# Ответ пункта 6\n",
    "X_test = vec.transform(X_t)\n",
    "print \" \".join(map(str, clf.predict(X_test)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Пункт 7"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.78\n"
     ]
    }
   ],
   "source": [
    "output = cross_val_score(LogisticRegression(), CountVectorizer(ngram_range=(2,2)).fit_transform(texts), lab_codes, scoring='f1').mean()\n",
    "print \"%.2f\" % output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.67\n"
     ]
    }
   ],
   "source": [
    "output = cross_val_score(LogisticRegression(), CountVectorizer(ngram_range=(3,3)).fit_transform(texts), lab_codes, scoring='f1').mean()\n",
    "print \"%.2f\" % output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.91\n"
     ]
    }
   ],
   "source": [
    "output = cross_val_score(LogisticRegression(), CountVectorizer(ngram_range=(1,3)).fit_transform(texts), lab_codes, scoring='f1').mean()\n",
    "print \"%.2f\" % output"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Пункт 8"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.naive_bayes import MultinomialNB"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.676920431076\n",
      "0.405096054216\n",
      "0.909900868195\n"
     ]
    }
   ],
   "source": [
    "print cross_val_score(MultinomialNB(), CountVectorizer(ngram_range=(2,2)).fit_transform(texts), lab_codes, scoring='f1').mean()\n",
    "print cross_val_score(MultinomialNB(), CountVectorizer(ngram_range=(3,3)).fit_transform(texts), lab_codes, scoring='f1').mean()\n",
    "print cross_val_score(MultinomialNB(), CountVectorizer(ngram_range=(1,3)).fit_transform(texts), lab_codes, scoring='f1').mean()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Пункт 9"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.797003520966\n"
     ]
    }
   ],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "\n",
    "print cross_val_score(MultinomialNB(), TfidfVectorizer().fit_transform(texts), lab_codes, scoring='f1').mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.pipeline import Pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.866600422941\n"
     ]
    }
   ],
   "source": [
    "pipeline = Pipeline([('vect', TfidfVectorizer()), ('clf', LogisticRegression())])\n",
    "print cross_val_score(pipeline, texts, lab_codes, scoring='f1').mean()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Пункт 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "pipeline = Pipeline([('vect', CountVectorizer()), ('clf', LogisticRegression())])\n",
    "\n",
    "tuned_parameters = [{'vect__binary': [True, False]}]\n",
    "\n",
    "clf = GridSearchCV(pipeline, tuned_parameters, scoring='f1')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GridSearchCV(cv=None, error_score='raise',\n",
       "       estimator=Pipeline(steps=[('vect', CountVectorizer(analyzer=u'word', binary=False, decode_error=u'strict',\n",
       "        dtype=<type 'numpy.int64'>, encoding=u'utf-8', input=u'content',\n",
       "        lowercase=True, max_df=1.0, max_features=None, min_df=1,\n",
       "        ngram_range=(1, 1), preprocessor=None, stop_words=None,\n",
       "        st...ty='l2', random_state=None, solver='liblinear', tol=0.0001,\n",
       "          verbose=0, warm_start=False))]),\n",
       "       fit_params={}, iid=True, n_jobs=1,\n",
       "       param_grid=[{'vect__binary': [True, False]}],\n",
       "       pre_dispatch='2*n_jobs', refit=True, return_train_score=True,\n",
       "       scoring='f1', verbose=0)"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf.fit(texts, lab_codes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Kirill\\Anaconda2\\lib\\site-packages\\sklearn\\model_selection\\_search.py:662: DeprecationWarning: The grid_scores_ attribute was deprecated in version 0.18 in favor of the more elaborate cv_results_ attribute. The grid_scores_ attribute will not be available from 0.20\n",
      "  DeprecationWarning)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[mean: 0.92726, std: 0.00685, params: {'vect__binary': True},\n",
       " mean: 0.92559, std: 0.00164, params: {'vect__binary': False}]"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf.grid_scores_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "## Выводы\n",
    "Собственно какие выводы можно сделать:\n",
    "1. CountVectorizer обгоняет MultinomialNB.\n",
    "2. CountVectorizer лучше работает без n-грамм вообще. Попробую предположить, что это из-за того, что в спаме как правило нет длинных словосочетаний. Всё ограничивается некими специфическими для спама словами. К примеру, глаголы: \"Спешите!\", \"Купите\" т.п.\n",
    "3. То, что мы запускаем TfidfVectorizer на всех текстах вносит свой вклад в переобучение, ухудшая результат на кросс-валидации."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
